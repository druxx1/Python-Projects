{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebbaf01f",
   "metadata": {},
   "source": [
    "# Project Scenario\n",
    "<br>\n",
    "A multi-national firm has hired you as a data engineer. Your job is to access and process data as per requirements.\n",
    "\n",
    "Your boss asked you to compile the list of the top 10 largest banks in the world ranked by market capitalization in billion USD. Further, you need to transform the data and store it in USD, GBP, EUR, and INR per the exchange rate information made available to you as a CSV file. You should save the processed information table locally in a CSV format and as a database table. Managers from different countries will query the database table to extract the list and note the market capitalization value in their own currency.\n",
    "<br><br>\n",
    "## Directions\n",
    "\n",
    "1. Write a function to extract the tabular information from the given URL under the heading By Market Capitalization, and save it to a data frame.<br><br>\n",
    "2. Write a function to transform the data frame by adding columns for Market Capitalization in GBP, EUR, and INR, rounded to 2 decimal places, based on the exchange rate information shared as a CSV file.<br><br>\n",
    "3. Write a function to load the transformed data frame to an output CSV file.<br><br>\n",
    "4. Write a function to load the transformed data frame to an SQL database server as a table.<br><br>\n",
    "5. Write a function to run queries on the database table.<br><br>\n",
    "6. Run the following queries on the database table:<br>\n",
    "a. Extract the information for the London office, that is Name and MC_GBP_Billion<br>\n",
    "b. Extract the information for the Berlin office, that is Name and MC_EUR_Billion<br>\n",
    "c. Extract the information for New Delhi office, that is Name and MC_INR_Billion<br><br>\n",
    "7. Write a function to log the progress of the code.<br><br>\n",
    "8. While executing the data initialization commands and function calls, maintain appropriate log entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96752718",
   "metadata": {},
   "source": [
    "## Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ff5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3 as sql\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53988934",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://web.archive.org/web/20230908091635%20/https://en.wikipedia.org/wiki/List_of_largest_banks\"\n",
    "extr_table_attr = [\"Name\", \"MC_USD_Billion\"]\n",
    "table_name = \"Largest_banks\"\n",
    "csv_path = \"Largest_banks_data.csv\"\n",
    "exchange_rate = \"exchange_rate.csv\"\n",
    "db_name = \"Banks.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb3a643",
   "metadata": {},
   "source": [
    "## Code - functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca4b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the extract function\n",
    "# I'm going to use a different approach from the practice project, because I think that approach is somehow unnecessary \n",
    "# and stressful for nothing. Using pd.read_html() is a lot easier, but it was really fun to learn another way to do it!\n",
    "\n",
    "def extract(url, table_attr):\n",
    "    \n",
    "    df = pd.read_html(url)[1]\n",
    "    df = df.iloc[:, 1:3]\n",
    "    df.columns = table_attr\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a9ae65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the transform function \n",
    "# We're going to add the GBP, EUR and INR currencies to the Data Frame, rounded to 2 decimal places. The exchange rates to be \n",
    "# used are located in the \"exchange_rate.csv\" file.\n",
    "\n",
    "def transform(df, exch_rate_csv):\n",
    "    \n",
    "    exch_rate = pd.read_csv(exchange_rate)\n",
    "    exch_rate = exch_rate.set_index('Currency')['Rate'].to_dict()\n",
    "    \n",
    "    for key, val in exch_rate.items(): # ensuring the rates to be float\n",
    "        exch_rate[key] = float(val)\n",
    "        \n",
    "    for curr, rate in exch_rate.items():\n",
    "        if curr != 'USD':\n",
    "            df[f'MC_{curr}_Billion'] = round(df['MC_USD_Billion'] * rate, 2)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86479143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the load functions\n",
    "# Both load functions will created here, the one to load the data to a csv file and the one to load to a database file.\n",
    "\n",
    "def load_to_csv(df, csv_path):\n",
    "    df.to_csv(csv_path)\n",
    "\n",
    "def load_to_db(df, sql_conn, table_name):\n",
    "    df.to_sql(table_name, sql_conn, if_exists= 'replace', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea52d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the query function\n",
    "# Writing a function to be able to run a SQL query in the database.\n",
    "\n",
    "def run_query(query_stmt, sql_conn):\n",
    "    print(query_stmt)\n",
    "    output = pd.read_sql(query_stmt, sql_conn)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54d188fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the log function\n",
    "# We'll be able to follow the ETL process\n",
    "\n",
    "def log(message):\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(\"code_log.txt\", \"a\") as file:\n",
    "        file.write(f\"{timestamp}: {message}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7276f436",
   "metadata": {},
   "source": [
    "## Code - Running the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01bfc624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM Largest_banks\n",
      "                                      Name  MC_USD_Billion  MC_EUR_Billion  \\\n",
      "0                           JPMorgan Chase          432.92          402.62   \n",
      "1                          Bank of America          231.52          215.31   \n",
      "2  Industrial and Commercial Bank of China          194.56          180.94   \n",
      "3               Agricultural Bank of China          160.68          149.43   \n",
      "4                                HDFC Bank          157.91          146.86   \n",
      "5                              Wells Fargo          155.87          144.96   \n",
      "6                        HSBC Holdings PLC          148.90          138.48   \n",
      "7                           Morgan Stanley          140.83          130.97   \n",
      "8                  China Construction Bank          139.82          130.03   \n",
      "9                            Bank of China          136.81          127.23   \n",
      "\n",
      "   MC_GBP_Billion  MC_INR_Billion  \n",
      "0          346.34        35910.71  \n",
      "1          185.22        19204.58  \n",
      "2          155.65        16138.75  \n",
      "3          128.54        13328.41  \n",
      "4          126.33        13098.63  \n",
      "5          124.70        12929.42  \n",
      "6          119.12        12351.26  \n",
      "7          112.66        11681.85  \n",
      "8          111.86        11598.07  \n",
      "9          109.45        11348.39  \n",
      "SELECT AVG(MC_GBP_Billion) FROM Largest_banks\n",
      "   AVG(MC_GBP_Billion)\n",
      "0              151.987\n",
      "SELECT Name from Largest_banks LIMIT 5\n",
      "                                      Name\n",
      "0                           JPMorgan Chase\n",
      "1                          Bank of America\n",
      "2  Industrial and Commercial Bank of China\n",
      "3               Agricultural Bank of China\n",
      "4                                HDFC Bank\n"
     ]
    }
   ],
   "source": [
    "log(\"Preliminaries complete. Initiating ETL process\")\n",
    "\n",
    "df = extract(url, extr_table_attr)\n",
    "\n",
    "log(\"Data extraction complete. Initiating Transformation process\")\n",
    "\n",
    "df = transform(df, exchange_rate)\n",
    "\n",
    "log(\"Data transformation complete. Initiating Loading process\")\n",
    "\n",
    "load_to_csv(df, csv_path)\n",
    "\n",
    "log(\"Data saved to CSV file. Innitiating SQL connection\")\n",
    "\n",
    "conn = sql.connect(db_name)\n",
    "\n",
    "log(\"SQL Connection initiated\")\n",
    "\n",
    "load_to_db(df, conn, table_name)\n",
    "\n",
    "log(\"Data loaded to Database as a table, executing queries\")\n",
    "\n",
    "run_query(\"SELECT * FROM Largest_banks\", conn)\n",
    "run_query(\"SELECT AVG(MC_GBP_Billion) FROM Largest_banks\", conn)\n",
    "run_query(\"SELECT Name from Largest_banks LIMIT 5\", conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "log(\"Process Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533809e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
